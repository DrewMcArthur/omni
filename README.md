# Omni <img src="logo.png" alt="" width="40px" height="40px">

Omni is a fully accessible digital space for sharing and discussing new knowledge.


# Introduction

Omni is helping to bring about the next generation of scholarly communications. The current scholarly publishing system is broken—new knowledge that benefits everyone is locked behind expensive paywalls and certain individuals/companies gain disproportionate levels of power and influence, allowing them to shape the system to work for them and not for the research ecosystem as a whole. More researchers and institutions are willing to fork the bill to allow anyone to read their research, but this can't possibly be sustainable. Simply put, scholars, institutions and citizens **are getting screwed**, and we're only just beginning to wake up to this fact—publishers still write the rules of the game.

# Motivation

The journal publication model made sense for the last few hundreds of years, but has rapidly become outdated within the new digital context. Although many journals have gone paperless, the *process* of scholarly communications has not changed—publishing and journal issuing has merely been converted to a digital format, and publishers have not made much use of the many powerful digital features we have today.

## False scarcity and unnecessary inaccessibility

The publishing system relies on false scarcity and artificial inaccessibility to reap the profits of the priceless work of authors. Not only is this unfair for researchers but prevents plenty of valuable knowledge being shared in research ecosystems and society more generally. Open Access was a good start to helping making research accessible, but there is still a lot of potential to improve on it, and in a way that is sustainable for the research ecosystem—not the publishing giants (who, arguably, do not deserve as much money as they get). Although editing is important, the system can't only work for the editors, which is why we're taking a stand *to put researchers, institutions and citizens first*.

A lot of useful work goes unpublished (e.g. null results, replication studies, full data sets, mistakes worth learning from, simulation code, and more). With no straightforward way to share this knowledge around, this often isn't easily accessible. 

## Perverse prestige system

The reputation of researchers in the current model is based on an overly reductive indicators of value, with the main culprit: the impact factor. The number of reads and citations of articles is [not enough to accurately represent](http://backreaction.blogspot.com/2017/03/academia-is-fucked-up-so-why-isnt.html) the value researchers contribute to the research ecosystem and/or to society. As scholarly communications is further digitised, we see an opportunity to make visible the many kinds of contributions people make to the ecosystem and, ideally, compensate them for these efforts. We need a [currency](http://www.artbrock.com/blog/designing-social-flows-chapter-6-designing-incentives) system which promotes good science and gets information to the relevant people, not a competitive model based on pumping out paper after paper.

## Impact vs. Quality

Although the validity of research is a prerequisite for getting an article through peer-review, it is treated as binary — valid or invalid. If there's anything I've learned from studying science it's that any claim is constantly being questioned. Any model of - or conclusion about - reality is only an assertation of an individual or group at a particular point in time, and rarely something that all parties will forever agree on. In the current system, such conclusions 'become truth' due to the decision of a small number of anonymous peer-reviewers, and not by the scholarly community collectively. We're not saying that all scholars are experts in every speciality and ought to state their opinion on every article, but that any member of the scholarly community *should be able to indicate* their understanding of an article's validity/quality from their epistemological position, at a particular point in time and always able to be updated.

Distinguishing *quality* and *impact* would allow researchers to be assessed on *process*, not only on the results of their research (where, arguably, luck can play a big part). We think if researchers develop good hypotheses and follow methodologies accurately, then they deserve credit regardless of the outcome. We see this as a way to encourage the publishing of replications and null results, as well as other 'less interesting' content which is often claimed to be the cornerstone of good research and lacking an incentive model. A indicator of validity or quality could identify researchers who follow *good process* and could redirect some flows of funding to the people who deserve better compensation.

## Stuck in static

Articles are still mostly treated as static PDFs with the figures and tables mashed obtrusively within the text. Do you find yourself scrolling up and down pages of text to find the figure being referenced, and then losing track of what you were just reading? This is an outdated way of viewing content and the rest of the internet has come a long way to displaying content effectively. We see the opportunity to enable readers to see the content they want to see in the ways that work best for them. Digital storytelling allows for non-traditional forms of communication, which, if applied to scholarly communications, could greatly increase the comprehensibility and accessibility of research, as well as enabling dynamic and large amounts of information to be displayed and interacted with nonlinearly. Increasing our expressive capacity is core to our ability to understand each other and collectively progress. It's time we moved on from purely static content.

## The power of collective intelligence

We've been interested in the developments of social networking platforms and how strongly they can shape human behaviour, for good or for worse. One one side you've got the likes of Facebook, Twitter and YouTube where users can quickly devolve into echo-chambers and polarised communities which breed outrage. On these platforms, content is often micromanaged to maximise user attention. On the other hand, communities like Wikipedia, Reddit, Stack Overflow and Quora (and sometimes even 4chan) are capable of aggregating high quality content and facilitating insightful and productive discussions. This shows the power our digital architectures and community spaces can have on individual and collective behaviour, and much could be learned from these to help us design systems which are intended to prioritise relevant content to users and to maximise collective intelligence.



# Omni: A fully accessible digital space for sharing and discussing new knowledge

Omni is an **open source** and **distributed** web application enabling scholars to share their research with all relevant audiences, without delays. There is no publisher or publishing in Omni, yet all processes of editing, peer-review, discussion and dissemination of new knowledge are performed by members of the scholarly community, and all valuable contributions are tracked. 

All data are stored in a Holochain *Distributed Hash Table (DHT)*, which is a shared database not owned by any central party, but is supported by all users of Omni using their currently unused spare computing resources. As long as some users are running the Omni application, no one can shut it down. Since everyone owns their own data in Omni, no one can prevent an author from sharing their research to as many communities as they wish.

Omni is not a journal, but a *public digital space* for authors to present their research and receive feedback from anyone in the academic community. With an open peer-review system, and quality assurance protocols decided on by the Omni community, we see the potential for academic research and scholarly communications to improve dramatically.

We aren't the only ones in the open source community working on new tools for scholarly researchers, and neither are we the only ones aiming to decentralise the publishing system—namely, the [Aletheia](https://github.com/aletheia-foundation/aletheia-whitepaper/blob/master/WHITE-PAPER.md) application built on Ethereum—but we see building Omni on Holochain [as the best way](https://github.com/holochain/holochain-proto/wiki/FAQ) to pull these efforts together into an efficient and scalable distributed application, uninhibited by the high costs and limitations of blockchain. 

## Holochain Backend

The interoperability of Holochain applications means Omni can immediately benefit from the work of other open source developers. Holochain also enables the community to administrate the Omni application themselves (much more simply than Ethereum DAOs), making it the way they want it—not just how we think it should be. Again, all of these can be achieved at much lower costs than an Ethereum version of Omni would. Holochain is an environmentally sustainable to blockchain as no computing power is wasted on busywork. Holochain is cryptographically secure and tamper-proof, and Holochain applications can't 'go down' as long as at least one computer is running the application—the Omni archive of research will never disappear. Even if millions of users suddenly dropped off the Omni network, all of the data would still be available.

You can learn more about the Holochain networking protocol [here](https://www.notion.so/Holochain-Reading-List-352388be758f4356a6da1fbb7962f87c).

## Writing and Co-Writing

## Editing and 'Peer-To-Peer'-Review

## Blocks

## Omni Communities
